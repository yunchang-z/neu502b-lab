{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `fMRI-04`: Subject-level analysis\n",
    "In this notebook, we demonstrate a full first-level regression analysis (often referred to as the general linear model or GLM; [Friston et al., 1994](https://doi.org/10.1002/hbm.460020402)) on volumetric fMRI data preprocessed using fMRIPrep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Construct block design regressors\n",
    "\n",
    "In the first step, we construct the design matrix based on the fMRI task. Here we are analyzing a simple visual experiment using a flickering checkerboard to evoke responses in early visual cortex. We presented six blocks of a rotating visual checkerboard (20 s duration per block) to one participant. The total run is 250 volumes and the repetition time (TR) was 1 s. First, we'll load in the data and extract the event onsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_table\n",
    "\n",
    "# Define some acquisition parameters\n",
    "tr = 1\n",
    "n_trs = 250\n",
    "block_duration = 20\n",
    "\n",
    "# Load experimental events\n",
    "events_f = 'sub-01_task-visualcontrol_desc-events.tsv'\n",
    "events_df = read_table(events_f, sep='\\t')\n",
    "\n",
    "# Extract checkerboard block onsets\n",
    "onsets = events_df.query('event==\"Checkerboard\"')['onset'].values.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct boxcar stimuli marking the checkerboard blocks based on the onset times, block duration, and total run duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxcar regressors:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, convolve the boxcar regressors (representing rapid neural activity) with a canonical hemodynamic response function (HRF) to better capture BOLD activity (call this variable `blocks_hrf`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolve with HRF:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot both the original boxcar time series and the predicted BOLD response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot boxcar and HRF-convolved time series:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Prepare confound regressors\n",
    "\n",
    "In this next section, we prepare a handful of confound (or \"nuisance\") regressors. These variables are not of experimental interest, but are included so as to account for variance introduced by head motion, physiological fluctuations, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Motion regressors\n",
    "\n",
    "First, we load the confounds table created by fMRIPrep and extract six motion parameters returned by fMRIPrep's volume registration algorithm. (Note that the labels for different regressors vary with the version of fMRIPrep.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fMRIPrep confound regressors\n",
    "confounds_f = 'sub-01_task-visualcontrol_desc-confounds_regressors.tsv'\n",
    "confounds_df = read_table(confounds_f, sep='\\t')\n",
    "\n",
    "# Extract motion regressors\n",
    "hm_labels = ['X', 'Y', 'Z', 'RotX', 'RotY', 'RotZ']\n",
    "hm = confounds_df[hm_labels].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize these head motion regressors below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot head motion regressors:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Motion censoring\n",
    "\n",
    "We prepare the motion censoring time series (or \"motion scrubbers\") from the framewise displacement estimates returned by fMRIPrep. Motion censoring is intended to absorb the variance from volumes \"infected\" with large head motion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define FD threshold\n",
    "fd_threshold = 0.25\n",
    "\n",
    "# Extract framewise displacement from confounds table\n",
    "fd = confounds_df['FramewiseDisplacement'].values\n",
    "fd[np.isnan(fd)] = 0\n",
    "\n",
    "# Identify infected volumes\n",
    "bad_vols = np.argwhere(fd >= fd_threshold)\n",
    "print(f'{bad_vols.size} bad volumes detected')\n",
    "\n",
    "# Construct censor regressors\n",
    "censors = np.zeros((fd.shape[0], bad_vols.shape[0]))\n",
    "censors[bad_vols.T, np.arange(bad_vols.shape[0])] = 1\n",
    "censor_labels = [f'censor{c}' for c in np.arange(censors.shape[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the framewise displacement (FD) time series. Include a horizontal line demarcating the threshold and vertical lines marking any censored time points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot FD and censors:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Physiological regressors\n",
    "\n",
    "We'll also include physiological nuisance regressors from the anatomical CompCor (aCompCor) time series automatically generated by fMRIPrep. These regressors comprise the first five principal component (PC) time series extracted from cerebrospinal fluid (CSF) and white matter. Plot the aCompCor regressors below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract aCompCor signals from confounds table\n",
    "acompcor_n = 5\n",
    "acompcor_df = confounds_df.filter(regex='aCompCor').iloc[:, :acompcor_n]\n",
    "acompcor_labels = acompcor_df.columns.tolist()\n",
    "acompcor = acompcor_df.values\n",
    "\n",
    "# Plot aCompCor regressors:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assemble confound regressors\n",
    "\n",
    "Finally, we'll assemble the nuisance regressors into a single confound matrix. Each confound variable should correspond to a separate column in the confound matrix. Include a column of 1s as well (the intercept)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define intercept:\n",
    "\n",
    "# Stack nuisance regressors:\n",
    "\n",
    "# Keep track of confound labels:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Check collinearity\n",
    "\n",
    "In this optional step, we check the collinearity of our full design matrix. Collinearity is a condition in which some of the independent variables are highly correlated. Collinearity tends to create numerical instability in our regression and inflate the variance of the estimated regression coefficients. To check collinearity, we rely on the [variance inflation factor](https://en.wikipedia.org/wiki/Variance_inflation_factor). As a simple rule of thumb, VIF scores above 5 suggest problematic collinearity. We'll use Python's `statsmodels` package to inspect collinearity; if you don't have `statsmodels` installed, go to the command line, make sure your conda environment is activated, and run the following line: `conda install -c conda-forge statsmodels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Assemble all regressors\n",
    "X = np.column_stack([blocks_hrf, confounds])\n",
    "\n",
    "# Assemble all regressor labels\n",
    "regressor_labels = ['blocks'] + confound_labels\n",
    "\n",
    "# Check variance inflation factor\n",
    "vif = [variance_inflation_factor(X, i) for i in np.arange(X.shape[-1])]\n",
    "\n",
    "# Visualize collinearity\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "ax.bar(np.arange(len(vif)), vif, color='gray')\n",
    "ax.hlines(5, -0.5, len(vif) - 0.5, linestyle='--', color='.7', zorder=0)\n",
    "ax.set(xlim=(-0.5, len(vif) - 0.5), xticks=np.arange(len(vif)), \n",
    "       ylabel='VIF')\n",
    "ax.set_xticklabels(regressor_labels, rotation=90)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Prepare fMRI Data\n",
    "\n",
    "In this next step, we prepare the fMRI data for regression analysis. For the sake of computational efficiency, we'll only analyze one slice of the brain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and mask data\n",
    "\n",
    "Here we load one slice of functional data as well as an anatomical segmentation created by FreeSurfer [Fischl et al., 2002](https://doi.org/10.1016/S0896-6273(02)00569-X). We mask the functional data only to voxels inside the cortex (i.e. a \"gray matter mask\"): label `3` for left-hemisphere cortex and label `42` for right-hemisphere cortex in the segmentation atlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "# Load one slice of functional data\n",
    "bold_f = 'sub-01_task-visualcontrol_space-T1w_desc-preproc_bold.nii.gz'\n",
    "bold_img = nib.load(bold_f)\n",
    "bold = bold_img.get_fdata()\n",
    "print(f'Functional data shape: {bold.shape}')\n",
    "\n",
    "# Load anatomical segmentation\n",
    "aseg_f = 'sub-01_task-visualcontrol_space-T1w_desc-aseg_dseg.nii.gz'\n",
    "aseg_img = nib.load(aseg_f)\n",
    "aseg = aseg_img.get_fdata()\n",
    "print(f'Segmentation shape: {aseg.shape}')\n",
    "\n",
    "# Store indices corresponding to gray matter mask\n",
    "mask_img = nib.Nifti1Image(np.logical_or(aseg == 3,\n",
    "                                         aseg == 42).astype(float),\n",
    "                           affine=bold_img.affine)\n",
    "mask_bool = np.logical_or(aseg == 3,\n",
    "                          aseg == 42)\n",
    "mask_coords = np.where(mask_bool)\n",
    "\n",
    "# Apply gray matter mask\n",
    "bold_masked = bold[mask_coords]\n",
    "\n",
    "# Transpose data to shape (n_times, n_voxels)\n",
    "bold_masked = bold_masked.T\n",
    "print(f'Masked data shape: {bold_masked.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the anatomical segmentation of cortex as a sanity check. First, use `matshow` to plot the first time point of the (unmasked) BOLD data. Next, use `matshow` again to plot the gray matter mask on top of the BOLD image. (Hint: if you set the non-cortex values of the mask to `np.nan`, they'll be plotted transparently—but you may need to change the data type to do so.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cortex mask overlaid on BOLD image:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's z-score the BOLD time series for each voxel prior to further analysis. Call the z-scored BOLD data `Y` to fit with the usual regression notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score BOLD data:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Least-squares regression\n",
    "Using ordinary least squares (OLS) regression, we can now regress our design matrix against the observed BOLD data (including nuisance regressors to reduce noise). Using the indices from the anatomical segmentation, we then extract the regression coefficients ($\\beta$-coefficients) and store them in new maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run regression with basic OLS\n",
    "b, _, _, _ = np.linalg.lstsq(X, Y, rcond=-1)\n",
    "\n",
    "# Make beta coefficient brain map\n",
    "beta_map = np.zeros(aseg.shape)\n",
    "beta_map[mask_coords] = b[0]\n",
    "\n",
    "# Convert zero values to NaNs for plotting\n",
    "beta_map[beta_map == 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot betas overlaid on BOLD image:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can also replicate our entire analysis in relatively few lines of code (with even more bells and whistles) using Nilearn's [`FirstLevelModel`](https://nilearn.github.io/dev/modules/generated/nilearn.glm.first_level.FirstLevelModel.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "\n",
    "# Reformat inputs for Nilearn\n",
    "mask_img = nib.Nifti1Image(mask_bool.astype(float),\n",
    "                           affine=aseg_img.affine)\n",
    "checkerboard_df = events_df.query('event==\"Checkerboard\"')\n",
    "confounds_df = DataFrame({l: c for l, c in zip(confound_labels, confounds.T)\n",
    "                          if l != 'intercept'})\n",
    "\n",
    "# Intialize Nilearn's GLM\n",
    "glm = FirstLevelModel(t_r=1,\n",
    "                      mask_img=mask_img,\n",
    "                      noise_model='ar1',\n",
    "                      standardize=True,\n",
    "                      hrf_model='glover',\n",
    "                      drift_model='cosine',\n",
    "                      high_pass=1/128)\n",
    "\n",
    "# Fit the GLM to BOLD data\n",
    "glm.fit(bold_img, events=checkerboard_df, confounds=confounds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Nilearn's design matrix and plot it\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "\n",
    "design_matrix = glm.design_matrices_[0]\n",
    "plot_design_matrix(design_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create contrast vector for checkerboard vs baseline\n",
    "contrast = np.zeros(len(glm.design_matrices_[0].columns))\n",
    "contrast[0] = 1\n",
    "\n",
    "# Extract betas for contrast\n",
    "beta_map = glm.compute_contrast(contrast,\n",
    "               output_type='effect_size').get_fdata()\n",
    "beta_map[beta_map == 0] = np.nan\n",
    "\n",
    "# Plot betas overlaid on BOLD image\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.matshow(bold[..., 0, 0], cmap='binary_r')\n",
    "ax.matshow(beta_map[..., 0], cmap='RdBu_r', vmin=-2, vmax=2)\n",
    "ax.set(xticks=[], yticks=[]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "\n",
    "* Fischl, B., Salat, D. H., Busa, E., Albert, M., Dieterich, M., Haselgrove, C., van der Kouwe, A., Killiany, R., Kennedy, D., Klaveness, S., Montillo, A., Makris, N., Rosen, B., & Dale, A. M. (2002). Whole brain segmentation: automated labeling of neuroanatomical structures in the human brain. _Neuron_, _33_(3), 341–355. https://doi.org/10.1016/S0896-6273(02)00569-X\n",
    "\n",
    "* Friston, K. J., Holmes, A. P., Worsley, K. J., Poline, J. P., Frith, C. D., & Frackowiak, R. S. (1994). Statistical parametric maps in functional imaging: a general linear approach. _Human Brain Mapping_, _2_(4), 189–210. https://doi.org/10.1002/hbm.460020402"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
