{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "monthly-professor",
   "metadata": {},
   "source": [
    "# `comp-03`: Voxelwise encoding models\n",
    "This demo introduces forward encoding modelsâ€”that is, using regularized regression to predict voxelwise activity from an explicit model of the stimulus in left-out data. Here, we use a semantic forward encoding model capturing the meaning of words to predict fMRI activity while participants listen to a spoken narrative (similarly to e.g. [Huth et al., 2016](https://doi.org/10.1038/nature17637)). The words in each TR are assigned a vector (i.e. word embedding) representing their location in a high-dimensional semantic space. For each voxel, we'll fit a model that predicts the time series of brain activity from the semantic vectors assigned to eachtime point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-connecticut",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-weather",
   "metadata": {},
   "source": [
    "### Naturalistic story-listening dataset\n",
    "As an example, we'll use fMRI data collected for a single subject listening to a spoken story called \"[I Knew You Were Black](https://themoth.org/stories/i-knew-you-were-black)\" by Carol Daniel. These data are available as part of the publicly available [Narratives](https://github.com/snastase/narratives) collection ([Nastase et al., 2019](https://openneuro.org/datasets/ds002345)). Here, we'll download a single subject from the server for analysis. If you're working on the server, use `cp` on the command line to create a copy of the following file in your working directory; if you're working locally, use `scp` to download the file to your machine:\n",
    "\n",
    "`/jukebox/PNI-classes/students/NEU502/2023-NEU502B/brainiak-aperture-data/sub-284_task-black_space-MNI152NLin2009cAsym_res-native_desc-clean_bold.nii.gz`\n",
    "\n",
    "This dataset has been preprocessed using fMRIPrep with confound regression in AFNI. The functional data have been spatially normalized to a template in MNI space. To reduce computational demands, we compute parcel-wise ISCs using a cortical parcellation containing 400 parcels from Schaefer and colleages (2018). Load in the functional data and atlas. Use the parcellation to extract the mean functional time series for each parcel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filenames for intact notthefall data and Schaefer atlas\n",
    "func_fn = ('sub-284_task-black_space-MNI152NLin2009cAsym_res-native_desc-clean_bold.nii.gz')\n",
    "atlas_fn = ('Schaefer2018_400Parcels_17Networks_order_FSLMNI152_2.5mm.nii.gz')\n",
    "\n",
    "# Load in the Schaefer 400-parcel atlas\n",
    "atlas_nii = nib.load(atlas_fn)\n",
    "atlas_img = atlas_nii.get_fdata()\n",
    "\n",
    "# Load in intact functional data and compute parcel means:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0991da60-c67d-4904-a4db-cfa6aa042fe4",
   "metadata": {},
   "source": [
    "To orient ourselves a bit, let's try plotting the BOLD time series for an example parcel. Start with parcel `196` in left superior temporal auditory association cortex. After plotting the time series, plot the location of this parcel in the brain using `plot_stat_map`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time series for an example parcel:\n",
    "from nilearn.plotting import plot_stat_map\n",
    "\n",
    "\n",
    "# Plot parcel on MNI atlas:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-limitation",
   "metadata": {},
   "source": [
    "### Semantic encoding model\n",
    "We'll decompose the story stimulus into a series of semantic features based on a simple, widely used representation of word meaning called GloVe ([Pennington et al., 2014](http://dx.doi.org/10.3115/v1/D14-1162])). GloVe represents each word in a 300-dimensional semantic space where words that are nearer in space are more semantically similar based on co-occurrence statistics from a large corpus of text. We start with a time-stamped stimulus transcript. For each TR, we identify which words occurred in that TR, then assign that TR the semantic embeddings associated with each word. For TRs with multiple words, we average the semantic embeddings; for TRs with no words, we use a 300-dimensional vector of zeros; we exclude a small number of stop words. Finally, to account for the hemodynamic lag in fMRI, we create lagged versions of the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in time-stamped transcript\n",
    "transcript_fn = 'black_gentle.csv'\n",
    "transcript = pd.read_csv(transcript_fn, sep=',')\n",
    "\n",
    "# Stimulus is roughly 800 seconds long\n",
    "tr = 1.5\n",
    "stim_dur = 800\n",
    "stim_trs = 800 // tr\n",
    "\n",
    "# Convert transcript to list for simplicity\n",
    "transcript = transcript.values.tolist()\n",
    "\n",
    "# Loop through TRs\n",
    "transcript_trs = []\n",
    "for t in np.arange(stim_trs):\n",
    "    \n",
    "    # Container for words in this TR\n",
    "    tr_words = []\n",
    "    \n",
    "    # Check if upcoming word onset is in this TR\n",
    "    while t * tr < transcript[0][2] <= t * tr + tr:\n",
    "        \n",
    "        # If so, pop this word out of list and keep it\n",
    "        w = transcript.pop(0)\n",
    "        tr_words.append(w[0])\n",
    "        \n",
    "    # Append words and move to the next TR\n",
    "    transcript_trs.append(tr_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in dictionary of GloVe embeddings\n",
    "with open('glove_embeddings.json') as f:\n",
    "    glove = json.load(f)\n",
    "    \n",
    "# Load list of standard stop words\n",
    "stopwords = np.load('nltk_stopwords.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c35f4f-b7c8-4802-8557-427b65ca59c8",
   "metadata": {},
   "source": [
    "Now that we have a transcript, a dictionary of word embeddings, and a list of stop words, we're ready to construct our predictor matrix. For each TR, obtain the words from `transcript_trs`. If a word is in our list of stop words, ignore it; otherwise, obtain the GloVe embedding for that word. If there are multiple words in a TR (excluding stop words), average their word embeddings to obtain a single embedding per TR. If a TR is empty (i.e. contains no words), set the embedding to a zero vector of the same dimensionality as the other embeddings. Lastly, visualize the resulting predictor matrix; z-score each column (i.e. GloVe dimension) for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign GloVe embeddings to each TR:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictor matrix of GloVe embeddings:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0f0c5a-1b71-4ee8-bd70-511982da66ff",
   "metadata": {},
   "source": [
    "Now, we'll horizontally stack the predictor matrix at lags of 2, 3, 4, and 5 TRs (3, 4.5, 6, 7.5 seconds) to account for variability in hemodynamic lag. Here's one recipe to do this: For each lag, first create prepending zero vectors for each TR in the lag; next, create appending zero vectors corresponding to the difference between the longest lag and the current lag; then, concatenate the prepending and appending vectors at the beginning and end of the predictor matrix, respectively. Horizontally stack the lagged matrices, z-score each column in the lagged predictor matrix, and visualize the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporally delayed version of embeddings:\n",
    "lags = [2, 3, 4, 5]\n",
    "\n",
    "# Horizontally stack lagged embeddings:\n",
    "\n",
    "# Z-score embeddings:\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Plot lagged predictor matrix:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5087d9ae-7aa4-4e12-a1a1-f76704881c0a",
   "metadata": {},
   "source": [
    "The fMRI data were collected with an 8-TR buffer prior to the beginning of the story stimulus and a 9-TR buffer after the end of the story stimulus. Trim off the starting buffer TRs, as well as the ending buffer TRs (excluding TRs for the lags). This should finalize our predictor matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim fMRI data to match embeddings:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-virginia",
   "metadata": {},
   "source": [
    "### Ridge regression\n",
    "Next, we use ridge regression to predict the activity at each parcel from the semantic embeddings. Note that the model dimensionality ($300 * 4$ delays $= 1200$ dimensions) is much greater than the number of samples ($<550$ TRs). This means we'll need to impose strong regularization on the model. Use a split-half outer cross-validation scheme where we train the model on half of the story and test the model on the other half. To search for the best-performing regularization parameter, perform 5-fold inner cross-validation within each training set using `RidgeCV`; this will select the best parameter setting from the inner cross-validation fold within the training half to predict the test half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-half outer cross-validation fold:\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# Ridge regression with alpha grid and nested CV:\n",
    "from sklearn.linear_model import RidgeCV\n",
    "alphas = [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]\n",
    "\n",
    "# Loop through outer split-half cross-validation:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-hanging",
   "metadata": {},
   "source": [
    "### Evaluating model performance\n",
    "To evaluate the predictions of our model, we use the model weights estimated from the training data to predict the brain activity from semantic embeddings for the test data. We then assess the similarity between the predicted brain activity and the actual brain activity for the test data. Keeping with conventions in the literature, we use Pearson correlation to assess the match between predicted and actual brain activity (although this is not considered a good scoring metric in machine learning and there are many other options; e.g. $R^2$). For each parcel, compute the Pearson correlation between the actual and predicted test time series. Plot the predicted and actual time series for the superior temporal parcel `196` (z-score the actual and predicted time series for plotting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation between predicted and actual responses:\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "    \n",
    "# Plot predicted and actual response for example parcel:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e8473d-fb2c-45b9-b528-54d5dc469edf",
   "metadata": {},
   "source": [
    "Finally, we'll plot the prediction performance scores on the brain. Convert the parcel-level prediction scores back into voxel-level brain maps; that is, for every voxel in a given parcel, assign that voxel the parcel's prediction score. Visualize the resulting brain map using `plot_stat_map`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlations between actual and predicted responses:\n",
    "from nilearn.plotting import plot_stat_map\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-puzzle",
   "metadata": {},
   "source": [
    "#### References\n",
    "\n",
    "* Huth, A. G., De Heer, W. A., Griffiths, T. L., Theunissen, F. E., & Gallant, J. L. (2016). Natural speech reveals the semantic maps that tile human cerebral cortex. *Nature*, *532*(7600), 453-458. https://doi.org/10.1038/nature17637\n",
    "\n",
    "* Nastase, S. A., Liu, Y.-F., Hillman, H., Zadbood, A., Hasenfratz, L., Keshavarzian, N., Chen, J., Honey, C. J., Yeshurun, Y., Regev, M., Nguyen, M., Chang, C. H. C., Baldassano, C., Lositsky, O., Simony, E., Chow, M. A., Leong, Y. C., Brooks, P. P., Micciche, E., Choe, G., Goldstein, A., Vanderwal, T., Halchenko, Y. O., Norman, K. A., & Hasson, U. (2020). Narratives: fMRI data for evaluating models of naturalistic language comprehension. *bioRxiv*. https://doi.org/10.1101/2020.12.23.424091\n",
    "\n",
    "* Pennington, J., Socher, R., & Manning, C. D. (2014, October). GloVe: Global Vectors for Word Representation. In *Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)* (pp. 1532-1543). https://www.aclweb.org/anthology/D14-1162\n",
    "\n",
    "* Schaefer, A., Kong, R., Gordon, E. M., Laumann, T. O., Zuo, X. N., Holmes, A. J., ... & Yeo, B. T. (2018). Local-global parcellation of the human cerebral cortex from intrinsic functional connectivity MRI. Cerebral cortex, 28(9), 3095-3114. https://doi.org/10.1093/cercor/bhx179"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
