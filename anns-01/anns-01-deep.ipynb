{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df2cae92-e267-4b37-8690-feabdd1e2f56",
   "metadata": {},
   "source": [
    "# `anns-01`: Deep learning\n",
    "In this lab, we'll explore some common architectures for deep neural networks. You'll need to install [PyTorch](https://pytorch.org/) in your conda environment: `conda install pytorch torchvision -c pytorch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f328c71a-b067-4170-a3f2-2767915e4e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3102387a-8c7a-4a15-beab-328d8363c406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "# Get device for training (e.g. MacOS 'mps')\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8108cfb6-d941-4bf8-99b9-dd4334f15c81",
   "metadata": {},
   "source": [
    "### Multilayer perceptron\n",
    "In the following exercise, we'll (de)construct a fully-connected feedforward network (i.e. multilayer perceptron; MLP). We'll use the rectified linear unit (ReLU) nonlinearity at hidden and output layers. This network will take as input pixels from MNIST images of handwritten digits and learn to output the correct digit label $0$ to $9$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1702790e-c550-46a2-9597-5f2dae3f2120",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e096feb5-1b44-4a41-a249-738066afcece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bca3432-7621-4be7-bf40-1b648e336f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Create a random image and confirm shape\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eb69d88-a7f8-4dec-8d93-de0713f3f61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "# Flatten image and inspect shape\n",
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a234b7e-8b6c-4a48-823e-ffdb72b0b3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "# Pass flattened input image through first layer\n",
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e2a36a4-1e7f-4608-af82-3b3855eb4eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[-0.1585, -0.0761,  0.8172, -0.2947,  0.0818, -0.2155,  0.0335,  0.0949,\n",
      "         -0.1370,  0.0369,  0.4356,  0.0510,  0.5128,  0.3135, -0.7414,  0.0195,\n",
      "          0.3077, -0.2673,  0.1592, -0.2009],\n",
      "        [-0.1645,  0.2207,  0.5236, -0.4695,  0.0641,  0.0228,  0.3479, -0.1545,\n",
      "         -0.2638, -0.1316,  0.2148,  0.0836,  0.5628,  0.1235, -0.2305,  0.5003,\n",
      "          0.3878, -0.0635,  0.1874, -0.1378],\n",
      "        [-0.3326, -0.0190,  0.7332,  0.0631, -0.0890,  0.1963,  0.2606, -0.2756,\n",
      "         -0.4416, -0.0745,  0.1508, -0.4680,  0.5920,  0.1180, -0.5592,  0.2552,\n",
      "          0.4084,  0.0078,  0.4298, -0.2247]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.0000, 0.0000, 0.8172, 0.0000, 0.0818, 0.0000, 0.0335, 0.0949, 0.0000,\n",
      "         0.0369, 0.4356, 0.0510, 0.5128, 0.3135, 0.0000, 0.0195, 0.3077, 0.0000,\n",
      "         0.1592, 0.0000],\n",
      "        [0.0000, 0.2207, 0.5236, 0.0000, 0.0641, 0.0228, 0.3479, 0.0000, 0.0000,\n",
      "         0.0000, 0.2148, 0.0836, 0.5628, 0.1235, 0.0000, 0.5003, 0.3878, 0.0000,\n",
      "         0.1874, 0.0000],\n",
      "        [0.0000, 0.0000, 0.7332, 0.0631, 0.0000, 0.1963, 0.2606, 0.0000, 0.0000,\n",
      "         0.0000, 0.1508, 0.0000, 0.5920, 0.1180, 0.0000, 0.2552, 0.4084, 0.0078,\n",
      "         0.4298, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Introduce nonlinearity ReLU\n",
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a444a552-d5cc-43c7-9563-3c8c423a92c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain these operations into sequence\n",
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21dea576-0d0b-4c23-beb7-d536b603f1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax predictions into probability distribution\n",
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a466c77-510c-4df0-8058-b281e1e3181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6de37cc-4d19-4fe5-b2b2-31dacb6b9fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "584752ad-2bc4-4fb9-b840-ed7cfb084030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize an example MNIST digit\n",
    "mnist_id = 0\n",
    "plt.matshow(X[mnist_id, 0], cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94da2dea-dde7-44f0-823d-ffdaabf738b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Redefine our model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33778971-6d2d-4220-b992-267f354ba2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81df5516-9ea1-4b66-a89d-568b947bb3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    # Train the model\n",
    "    model.train()\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Clear gradients for this training step\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Compute gradients via backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Apply gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16be8b49-379c-4eb5-ae1d-b3f22bdab415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    # Test the model\n",
    "    model.eval()\n",
    "\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # Compute model predictions on test set\n",
    "            pred = model(X)\n",
    "            \n",
    "            # Compute loss between predicted and actual labels\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            \n",
    "            # Number correct for accuracy\n",
    "            correct += (pred.max(axis=1).indices == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test error: \\n Accuracy: {(100*correct):>0.1f}%, mean loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2790151c-33e6-45af-a5dd-274d9b86de9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.310624  [    0/60000]\n",
      "loss: 2.305503  [ 6400/60000]\n",
      "loss: 2.291320  [12800/60000]\n",
      "loss: 2.280551  [19200/60000]\n",
      "loss: 2.293427  [25600/60000]\n",
      "loss: 2.285117  [32000/60000]\n",
      "loss: 2.264528  [38400/60000]\n",
      "loss: 2.275290  [44800/60000]\n",
      "loss: 2.263194  [51200/60000]\n",
      "loss: 2.235015  [57600/60000]\n",
      "Test error: \n",
      " Accuracy: 29.3%, mean loss: 2.255978 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.262526  [    0/60000]\n",
      "loss: 2.255690  [ 6400/60000]\n",
      "loss: 2.249236  [12800/60000]\n",
      "loss: 2.217116  [19200/60000]\n",
      "loss: 2.243402  [25600/60000]\n",
      "loss: 2.233561  [32000/60000]\n",
      "loss: 2.203324  [38400/60000]\n",
      "loss: 2.227207  [44800/60000]\n",
      "loss: 2.199746  [51200/60000]\n",
      "loss: 2.164375  [57600/60000]\n",
      "Test error: \n",
      " Accuracy: 47.9%, mean loss: 2.187573 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.192581  [    0/60000]\n",
      "loss: 2.180966  [ 6400/60000]\n",
      "loss: 2.184733  [12800/60000]\n",
      "loss: 2.119088  [19200/60000]\n",
      "loss: 2.162790  [25600/60000]\n",
      "loss: 2.148340  [32000/60000]\n",
      "loss: 2.101796  [38400/60000]\n",
      "loss: 2.143165  [44800/60000]\n",
      "loss: 2.091016  [51200/60000]\n",
      "loss: 2.044850  [57600/60000]\n",
      "Test error: \n",
      " Accuracy: 61.4%, mean loss: 2.069307 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.073507  [    0/60000]\n",
      "loss: 2.051168  [ 6400/60000]\n",
      "loss: 2.071557  [12800/60000]\n",
      "loss: 1.952809  [19200/60000]\n",
      "loss: 2.016578  [25600/60000]\n",
      "loss: 1.994779  [32000/60000]\n",
      "loss: 1.928623  [38400/60000]\n",
      "loss: 1.992774  [44800/60000]\n",
      "loss: 1.903234  [51200/60000]\n",
      "loss: 1.845471  [57600/60000]\n",
      "Test error: \n",
      " Accuracy: 68.7%, mean loss: 1.865728 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.874602  [    0/60000]\n",
      "loss: 1.830744  [ 6400/60000]\n",
      "loss: 1.872694  [12800/60000]\n",
      "loss: 1.691252  [19200/60000]\n",
      "loss: 1.766224  [25600/60000]\n",
      "loss: 1.733853  [32000/60000]\n",
      "loss: 1.661858  [38400/60000]\n",
      "loss: 1.753852  [44800/60000]\n",
      "loss: 1.624973  [51200/60000]\n",
      "loss: 1.560007  [57600/60000]\n",
      "Test error: \n",
      " Accuracy: 73.6%, mean loss: 1.566632 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Fit the model!\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a858308-1bce-41a3-8c98-36d21abc5063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"6\", Actual: \"5\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize model predictions from the test set\n",
    "classes = np.arange(10)\n",
    "test_id = 8\n",
    "\n",
    "x, y = test_data[test_id][0], test_data[test_id][1]\n",
    "with torch.no_grad():\n",
    "    plt.matshow(x[0], cmap='gray')\n",
    "    x, y = x.to(device), y\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred.max(axis=1).indices], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c7f659-6906-4b8d-b75b-c80595dc3d44",
   "metadata": {},
   "source": [
    "### Convolutional neural network\n",
    "In this excercise, we'll perform the same digit recognition task using a convolutional neural network (CNN). For brevity, the CNN will comprise two convolutional layers followed by max-pooling layers, culminating in a single fully-connected layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b90f50eb-9d4f-4d4f-9048-399992ae5c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=4,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(16, 32, 4, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "\n",
    "        # Fully connected layer outputs 10 classes\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        # Flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        output = self.out(x)\n",
    "        return output\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cbf5dd-6d0b-45b8-9458-e359cace5328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define same loss and optimizer as above\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f60dea-266e-4763-9b3b-b3238305f6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.301215  [    0/60000]\n",
      "loss: 2.286668  [ 6400/60000]\n",
      "loss: 2.272518  [12800/60000]\n",
      "loss: 2.255121  [19200/60000]\n",
      "loss: 2.246310  [25600/60000]\n",
      "loss: 2.242125  [32000/60000]\n",
      "loss: 2.194222  [38400/60000]\n",
      "loss: 2.201905  [44800/60000]\n",
      "loss: 2.153085  [51200/60000]\n",
      "loss: 2.086468  [57600/60000]\n",
      "Test error: \n",
      " Accuracy: 63.5%, mean loss: 2.085685 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.096876  [    0/60000]\n",
      "loss: 2.009386  [ 6400/60000]\n",
      "loss: 1.973640  [12800/60000]\n",
      "loss: 1.821295  [19200/60000]\n",
      "loss: 1.735722  [25600/60000]\n",
      "loss: 1.620451  [32000/60000]\n",
      "loss: 1.373021  [38400/60000]\n",
      "loss: 1.417534  [44800/60000]\n",
      "loss: 1.186285  [51200/60000]\n",
      "loss: 1.018133  [57600/60000]\n",
      "Test error: \n",
      " Accuracy: 79.4%, mean loss: 0.962633 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.001786  [    0/60000]\n",
      "loss: 0.791728  [ 6400/60000]\n",
      "loss: 0.767685  [12800/60000]\n",
      "loss: 0.719919  [19200/60000]\n",
      "loss: 0.657966  [25600/60000]\n",
      "loss: 0.634363  [32000/60000]\n",
      "loss: 0.502056  [38400/60000]\n",
      "loss: 0.697732  [44800/60000]\n",
      "loss: 0.622378  [51200/60000]\n",
      "loss: 0.563141  [57600/60000]\n",
      "Test error: \n",
      " Accuracy: 85.9%, mean loss: 0.518135 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.548324  [    0/60000]\n",
      "loss: 0.458907  [ 6400/60000]\n",
      "loss: 0.413920  [12800/60000]\n",
      "loss: 0.479900  [19200/60000]\n",
      "loss: 0.438459  [25600/60000]\n",
      "loss: 0.459988  [32000/60000]\n",
      "loss: 0.327320  [38400/60000]\n",
      "loss: 0.532391  [44800/60000]\n",
      "loss: 0.491124  [51200/60000]\n",
      "loss: 0.475855  [57600/60000]\n",
      "Test error: \n",
      " Accuracy: 88.3%, mean loss: 0.410592 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.430083  [    0/60000]\n",
      "loss: 0.389271  [ 6400/60000]\n",
      "loss: 0.317539  [12800/60000]\n",
      "loss: 0.411255  [19200/60000]\n",
      "loss: 0.353367  [25600/60000]\n",
      "loss: 0.410035  [32000/60000]\n",
      "loss: 0.256038  [38400/60000]\n",
      "loss: 0.470758  [44800/60000]\n",
      "loss: 0.428096  [51200/60000]\n",
      "loss: 0.444553  [57600/60000]\n",
      "Test error: \n",
      " Accuracy: 89.5%, mean loss: 0.361480 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Fit the model!\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
